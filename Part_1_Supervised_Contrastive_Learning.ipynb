{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syedanida/Computer-Vision/blob/main/Part_1_Supervised_Contrastive_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HV6rO_x-Qqjo",
        "outputId": "ef93ebbf-89c7-4cbe-d7e2-766bebaf8c39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons) (24.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.2\n",
            "    Uninstalling typeguard-4.4.2:\n",
            "      Successfully uninstalled typeguard-4.4.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install tensorflow-addons\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install pandas\n",
        "!pip install seaborn\n",
        "!pip install scikit-learn\n",
        "!pip install opencv-python\n",
        "!pip install pillow\n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lvy-Z16lPsZ0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "import time\n",
        "from sklearn.manifold import TSNE\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten, Dropout, GlobalAveragePooling2D, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRZUf_u0Ptpy"
      },
      "outputs": [],
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw3_hVEoPuzd"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "BATCH_SIZE = 128\n",
        "IMG_SIZE = 32\n",
        "PROJECTION_DIM = 128\n",
        "TEMPERATURE = 0.1\n",
        "EPOCHS = 20\n",
        "LEARNING_RATE = 0.001\n",
        "DROPOUT_RATE = 0.5\n",
        "NUM_CLASSES = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE1dlZcBPx8L"
      },
      "outputs": [],
      "source": [
        "# Load CIFAR-10 dataset\n",
        "def load_cifar10_dataset():\n",
        "    \"\"\"Load and preprocess CIFAR-10 dataset\"\"\"\n",
        "    print(\"Loading CIFAR-10 dataset...\")\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "    # Convert labels to 1D arrays\n",
        "    y_train = tf.squeeze(y_train)\n",
        "    y_test = tf.squeeze(y_test)\n",
        "\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    x_train = tf.cast(x_train, tf.float32) / 255.0\n",
        "    x_test = tf.cast(x_test, tf.float32) / 255.0\n",
        "\n",
        "    print(f\"Training data shape: {x_train.shape}, Training labels shape: {y_train.shape}\")\n",
        "    print(f\"Test data shape: {x_test.shape}, Test labels shape: {y_test.shape}\")\n",
        "\n",
        "    # Get class names\n",
        "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "                   'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test), class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3FYdH9LPyo6"
      },
      "outputs": [],
      "source": [
        "# Create TensorFlow datasets\n",
        "def create_datasets(x_train, y_train, x_test, y_test, batch_size=BATCH_SIZE):\n",
        "    \"\"\"Create TensorFlow datasets for training and testing\"\"\"\n",
        "\n",
        "    # Create training dataset\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "    # Create test dataset\n",
        "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "    test_dataset = test_dataset.batch(batch_size)\n",
        "\n",
        "    return train_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HT_QMnyQPymP"
      },
      "outputs": [],
      "source": [
        "# Data augmentation function\n",
        "def get_data_augmentation():\n",
        "    \"\"\"Create data augmentation model\"\"\"\n",
        "    data_augmentation = tf.keras.Sequential([\n",
        "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "        tf.keras.layers.RandomRotation(0.1),\n",
        "        tf.keras.layers.RandomZoom(0.1),\n",
        "        tf.keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "    ])\n",
        "    return data_augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k5_bVxcP2mG"
      },
      "outputs": [],
      "source": [
        "# Create ResNet-based encoder\n",
        "def create_encoder():\n",
        "    \"\"\"Create ResNet-based encoder for image feature extraction\"\"\"\n",
        "    # Use a simplified architecture for CIFAR-10\n",
        "    inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "    # Initial convolutional block\n",
        "    x = Conv2D(64, 3, strides=1, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    # Residual blocks\n",
        "    for filters in [64, 128, 256]:\n",
        "        # First block with downsampling\n",
        "        x = Conv2D(filters, 3, strides=2, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "\n",
        "        # Second block with skip connection\n",
        "        residual = x\n",
        "        x = Conv2D(filters, 3, strides=1, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = Conv2D(filters, 3, strides=1, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = tf.keras.layers.add([x, residual])\n",
        "        x = Activation(\"relu\")(x)\n",
        "\n",
        "    # Global pooling\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Dense(PROJECTION_DIM)(x)\n",
        "\n",
        "    # Create model\n",
        "    encoder = Model(inputs=inputs, outputs=outputs, name=\"encoder\")\n",
        "\n",
        "    return encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PMHabkCP2jS"
      },
      "outputs": [],
      "source": [
        "# Create projection head for contrastive learning\n",
        "def create_projection_head():\n",
        "    \"\"\"Create projection head for contrastive learning\"\"\"\n",
        "    inputs = Input(shape=(PROJECTION_DIM,))\n",
        "    x = Dense(PROJECTION_DIM)(inputs)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    outputs = Dense(PROJECTION_DIM)(x)\n",
        "\n",
        "    projection_head = Model(inputs, outputs, name=\"projection_head\")\n",
        "    return projection_head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWVpJbbFP2gY"
      },
      "outputs": [],
      "source": [
        "# Create classification head\n",
        "def create_classification_head():\n",
        "    \"\"\"Create classification head\"\"\"\n",
        "    inputs = Input(shape=(PROJECTION_DIM,))\n",
        "    x = Dense(PROJECTION_DIM // 2)(inputs)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Dropout(DROPOUT_RATE)(x)\n",
        "    outputs = Dense(NUM_CLASSES, activation=\"softmax\")(inputs)\n",
        "\n",
        "    classification_head = Model(inputs, outputs, name=\"classification_head\")\n",
        "    return classification_head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEobll6dP9zs"
      },
      "outputs": [],
      "source": [
        "# Supervised Contrastive Loss function\n",
        "class SupervisedContrastiveLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, temperature=TEMPERATURE, name=\"supervised_contrastive_loss\"):\n",
        "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
        "        # Normalize feature vectors\n",
        "        feature_vectors = tf.math.l2_normalize(feature_vectors, axis=1)\n",
        "\n",
        "        # Get similarity matrix\n",
        "        similarity_matrix = tf.matmul(feature_vectors, feature_vectors, transpose_b=True)\n",
        "\n",
        "        # Scale by temperature\n",
        "        similarity_matrix = similarity_matrix / self.temperature\n",
        "\n",
        "        # Define labels equality\n",
        "        labels = tf.reshape(labels, [-1, 1])\n",
        "        mask_similar = tf.cast(tf.equal(labels, tf.transpose(labels)), tf.float32)\n",
        "\n",
        "        # Create identity mask to exclude self-contrast\n",
        "        batch_size = tf.shape(feature_vectors)[0]\n",
        "        mask_self = tf.eye(batch_size)\n",
        "\n",
        "        # Apply masks to exclude self-contrast and include only same-label pairs\n",
        "        mask_positives = mask_similar * (1.0 - mask_self)\n",
        "        mask_negatives = 1.0 - mask_self\n",
        "\n",
        "        # Count number of positives per sample\n",
        "        num_positives = tf.reduce_sum(mask_positives, axis=1)\n",
        "\n",
        "        # Calculate log-probabilities\n",
        "        exp_logits = tf.exp(similarity_matrix)\n",
        "        log_prob = similarity_matrix - tf.math.log(tf.reduce_sum(exp_logits * mask_negatives, axis=1, keepdims=True))\n",
        "\n",
        "        # Calculate mean of log-probabilities over positive samples\n",
        "        mean_log_prob_pos = tf.reduce_sum(mask_positives * log_prob, axis=1) / (num_positives + 1e-8)\n",
        "\n",
        "        # Return negative mean (for minimization)\n",
        "        loss = -tf.reduce_mean(mean_log_prob_pos)\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuYOfjt4QAlH"
      },
      "outputs": [],
      "source": [
        "# Traditional classification model approach\n",
        "def train_traditional_classification(x_train, y_train, x_test, y_test):\n",
        "    \"\"\"Train a traditional classification model\"\"\"\n",
        "    print(\"\\n--- Traditional Classification Approach ---\\n\")\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset, test_dataset = create_datasets(x_train, y_train, x_test, y_test)\n",
        "\n",
        "    # Create data augmentation model\n",
        "    data_augmentation = get_data_augmentation()\n",
        "\n",
        "    # Create encoder\n",
        "    encoder = create_encoder()\n",
        "\n",
        "    # Create input layer\n",
        "    inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "    # Apply data augmentation\n",
        "    x = data_augmentation(inputs)\n",
        "\n",
        "    # Apply encoder\n",
        "    features = encoder(x)\n",
        "\n",
        "    # Apply classification head\n",
        "    outputs = create_classification_head()(features)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs, outputs, name=\"traditional_classification_model\")\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "    )\n",
        "\n",
        "    # Create early stopping callback\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    print(\"Training traditional classification model...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=test_dataset,\n",
        "        callbacks=[early_stopping]\n",
        "    )\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "    # Evaluate model\n",
        "    loss, accuracy = model.evaluate(test_dataset, verbose=0)\n",
        "    print(f\"Test Loss: {loss:.4f}\")\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    return model, encoder, history, accuracy, training_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Trxd3m3rQEcL"
      },
      "outputs": [],
      "source": [
        "# Supervised contrastive learning approach\n",
        "def train_supervised_contrastive(x_train, y_train, x_test, y_test):\n",
        "    \"\"\"Train using supervised contrastive learning approach\"\"\"\n",
        "    print(\"\\n--- Supervised Contrastive Learning Approach ---\\n\")\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset, test_dataset = create_datasets(x_train, y_train, x_test, y_test)\n",
        "\n",
        "    # Create data augmentation model\n",
        "    data_augmentation = get_data_augmentation()\n",
        "\n",
        "    # Create encoder\n",
        "    encoder = create_encoder()\n",
        "\n",
        "    # Create projection head\n",
        "    projection_head = create_projection_head()\n",
        "\n",
        "    # Create early stopping callback\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    # Phase 1: Contrastive pre-training\n",
        "    print(\"Phase 1: Contrastive pre-training...\")\n",
        "\n",
        "    # Create pretraining model\n",
        "    inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    x = data_augmentation(inputs)\n",
        "    features = encoder(x)\n",
        "    projections = projection_head(features)\n",
        "    pretraining_model = Model(inputs, projections, name=\"pretraining_model\")\n",
        "\n",
        "    # Compile pretraining model\n",
        "    pretraining_model.compile(\n",
        "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "        loss=SupervisedContrastiveLoss(TEMPERATURE)\n",
        "    )\n",
        "\n",
        "    # Train pretraining model\n",
        "    start_time = time.time()\n",
        "\n",
        "    pretraining_history = pretraining_model.fit(\n",
        "        train_dataset,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=test_dataset,\n",
        "        callbacks=[early_stopping]\n",
        "    )\n",
        "\n",
        "    pretraining_time = time.time() - start_time\n",
        "    print(f\"Pretraining completed in {pretraining_time:.2f} seconds\")\n",
        "\n",
        "    # Phase 2: Classification training\n",
        "    print(\"Phase 2: Classification training...\")\n",
        "\n",
        "    # Freeze encoder\n",
        "    encoder.trainable = False\n",
        "\n",
        "    # Create classification model\n",
        "    inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    features = encoder(inputs)\n",
        "    outputs = create_classification_head()(features)\n",
        "    classification_model = Model(inputs, outputs, name=\"classification_model\")\n",
        "\n",
        "    # Compile classification model\n",
        "    classification_model.compile(\n",
        "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "    )\n",
        "\n",
        "    # Train classification model\n",
        "    classification_start_time = time.time()\n",
        "\n",
        "    classification_history = classification_model.fit(\n",
        "        train_dataset,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=test_dataset,\n",
        "        callbacks=[early_stopping]\n",
        "    )\n",
        "\n",
        "    classification_time = time.time() - classification_start_time\n",
        "    print(f\"Classification training completed in {classification_time:.2f} seconds\")\n",
        "\n",
        "    # Total training time\n",
        "    total_training_time = pretraining_time + classification_time\n",
        "    print(f\"Total training time: {total_training_time:.2f} seconds\")\n",
        "\n",
        "    # Evaluate model\n",
        "    loss, accuracy = classification_model.evaluate(test_dataset, verbose=0)\n",
        "    print(f\"Test Loss: {loss:.4f}\")\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Create combined history\n",
        "    combined_history = {\n",
        "        'pretraining_loss': pretraining_history.history['loss'],\n",
        "        'pretraining_val_loss': pretraining_history.history['val_loss'],\n",
        "        'classification_loss': classification_history.history['loss'],\n",
        "        'classification_val_loss': classification_history.history['val_loss'],\n",
        "        'accuracy': classification_history.history['sparse_categorical_accuracy'],\n",
        "        'val_accuracy': classification_history.history['val_sparse_categorical_accuracy'],\n",
        "    }\n",
        "\n",
        "    return classification_model, encoder, combined_history, accuracy, total_training_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pDaozwbQEZg"
      },
      "outputs": [],
      "source": [
        "def extract_embeddings(model, x_data, y_data, num_samples=1000):\n",
        "    \"\"\"Extract embeddings for visualization\"\"\"\n",
        "    # Select random samples\n",
        "    indices = np.random.choice(len(x_data), min(num_samples, len(x_data)), replace=False)\n",
        "\n",
        "    # Use NumPy indexing directly\n",
        "    x_samples = x_data[indices]\n",
        "    y_samples = y_data[indices]\n",
        "\n",
        "    # Create a model that outputs embeddings\n",
        "    embedding_model = Model(\n",
        "        inputs=model.input,\n",
        "        outputs=model.layers[-2].output\n",
        "    )\n",
        "\n",
        "    # Extract embeddings\n",
        "    embeddings = embedding_model.predict(x_samples)\n",
        "\n",
        "    return embeddings, y_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_6ppudlQEWm"
      },
      "outputs": [],
      "source": [
        "# Visualize embeddings with t-SNE\n",
        "def visualize_embeddings(embeddings, labels, class_names, title):\n",
        "    \"\"\"Visualize embeddings using t-SNE\"\"\"\n",
        "    print(f\"Visualizing embeddings using t-SNE: {title}\")\n",
        "\n",
        "    # Apply t-SNE\n",
        "    tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=42)\n",
        "    embeddings_2d = tsne.fit_transform(embeddings)\n",
        "\n",
        "    # Create DataFrame for easier plotting\n",
        "    df = pd.DataFrame({\n",
        "        'x': embeddings_2d[:, 0],\n",
        "        'y': embeddings_2d[:, 1],\n",
        "        'label': labels\n",
        "    })\n",
        "\n",
        "    # Create plot\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # Plot each class with a different color\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        mask = df['label'] == i\n",
        "        plt.scatter(\n",
        "            df.loc[mask, 'x'],\n",
        "            df.loc[mask, 'y'],\n",
        "            label=class_name,\n",
        "            alpha=0.7,\n",
        "            s=30\n",
        "        )\n",
        "\n",
        "    plt.title(title, fontsize=16)\n",
        "    plt.legend(title=\"Classes\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.xlabel(\"t-SNE Dimension 1\")\n",
        "    plt.ylabel(\"t-SNE Dimension 2\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{title.replace(' ', '_')}.png\", dpi=300, bbox_inches=\"tight\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whUNZKpEQK3M"
      },
      "outputs": [],
      "source": [
        "# Visualize training history\n",
        "def visualize_training_history(traditional_history, contrastive_history):\n",
        "    \"\"\"Visualize training history for both approaches\"\"\"\n",
        "    # Create figure\n",
        "    plt.figure(figsize=(15, 6))\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(\n",
        "        traditional_history.history['sparse_categorical_accuracy'],\n",
        "        label='Traditional (Train)'\n",
        "    )\n",
        "    plt.plot(\n",
        "        traditional_history.history['val_sparse_categorical_accuracy'],\n",
        "        label='Traditional (Val)'\n",
        "    )\n",
        "    plt.plot(\n",
        "        contrastive_history['accuracy'],\n",
        "        label='Contrastive (Train)'\n",
        "    )\n",
        "    plt.plot(\n",
        "        contrastive_history['val_accuracy'],\n",
        "        label='Contrastive (Val)'\n",
        "    )\n",
        "    plt.title('Accuracy Comparison', fontsize=14)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    # Plot loss (not directly comparable)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(\n",
        "        traditional_history.history['loss'],\n",
        "        label='Traditional (Train)'\n",
        "    )\n",
        "    plt.plot(\n",
        "        traditional_history.history['val_loss'],\n",
        "        label='Traditional (Val)'\n",
        "    )\n",
        "    plt.plot(\n",
        "        contrastive_history['classification_loss'],\n",
        "        label='Contrastive Classification (Train)'\n",
        "    )\n",
        "    plt.plot(\n",
        "        contrastive_history['classification_val_loss'],\n",
        "        label='Contrastive Classification (Val)'\n",
        "    )\n",
        "    plt.title('Loss Comparison', fontsize=14)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"training_history_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "    # Plot pretraining loss separately\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(\n",
        "        contrastive_history['pretraining_loss'],\n",
        "        label='Train'\n",
        "    )\n",
        "    plt.plot(\n",
        "        contrastive_history['pretraining_val_loss'],\n",
        "        label='Validation'\n",
        "    )\n",
        "    plt.title('Supervised Contrastive Pretraining Loss', fontsize=14)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Contrastive Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"pretraining_loss.png\", dpi=300, bbox_inches=\"tight\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqlwZJCeQOkR"
      },
      "outputs": [],
      "source": [
        "# Compare model performance\n",
        "def compare_performance(traditional_acc, contrastive_acc, traditional_time, contrastive_time):\n",
        "    \"\"\"Compare performance metrics between approaches\"\"\"\n",
        "    # Create figure\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot accuracy comparison\n",
        "    plt.subplot(1, 2, 1)\n",
        "    methods = ['Traditional', 'Supervised Contrastive']\n",
        "    accuracies = [traditional_acc, contrastive_acc]\n",
        "\n",
        "    bars = plt.bar(methods, accuracies, color=['#3498db', '#e74c3c'])\n",
        "    plt.title('Test Accuracy Comparison', fontsize=14)\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.ylim(0, 1.0)\n",
        "\n",
        "    # Add accuracy values on top of bars\n",
        "    for bar, acc in zip(bars, accuracies):\n",
        "        plt.text(\n",
        "            bar.get_x() + bar.get_width() / 2,\n",
        "            bar.get_height() + 0.01,\n",
        "            f\"{acc:.4f}\",\n",
        "            ha='center',\n",
        "            fontweight='bold'\n",
        "        )\n",
        "\n",
        "    # Plot training time comparison\n",
        "    plt.subplot(1, 2, 2)\n",
        "    times = [traditional_time, contrastive_time]\n",
        "\n",
        "    bars = plt.bar(methods, times, color=['#3498db', '#e74c3c'])\n",
        "    plt.title('Training Time Comparison', fontsize=14)\n",
        "    plt.ylabel('Time (seconds)')\n",
        "\n",
        "    # Add time values on top of bars\n",
        "    for bar, t in zip(bars, times):\n",
        "        plt.text(\n",
        "            bar.get_x() + bar.get_width() / 2,\n",
        "            bar.get_height() + 20,\n",
        "            f\"{t:.0f}s\",\n",
        "            ha='center',\n",
        "            fontweight='bold'\n",
        "        )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"performance_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AgvkRLnQRNE"
      },
      "outputs": [],
      "source": [
        "# Main function\n",
        "def main():\n",
        "    print(\"Supervised Contrastive Learning vs Traditional Classification\")\n",
        "\n",
        "    # Load CIFAR-10 dataset\n",
        "    (x_train, y_train), (x_test, y_test), class_names = load_cifar10_dataset()\n",
        "\n",
        "    # Train traditional classification model\n",
        "    traditional_model, traditional_encoder, traditional_history, traditional_acc, traditional_time = train_traditional_classification(\n",
        "        x_train, y_train, x_test, y_test\n",
        "    )\n",
        "\n",
        "    # Train supervised contrastive model\n",
        "    contrastive_model, contrastive_encoder, contrastive_history, contrastive_acc, contrastive_time = train_supervised_contrastive(\n",
        "        x_train, y_train, x_test, y_test\n",
        "    )\n",
        "\n",
        "    # Extract embeddings for visualization\n",
        "    traditional_embeddings, traditional_labels = extract_embeddings(\n",
        "        traditional_model, x_test, y_test\n",
        "    )\n",
        "\n",
        "    contrastive_embeddings, contrastive_labels = extract_embeddings(\n",
        "        contrastive_model, x_test, y_test\n",
        "    )\n",
        "\n",
        "    # Visualize embeddings\n",
        "    visualize_embeddings(\n",
        "        traditional_embeddings, traditional_labels, class_names,\n",
        "        \"Traditional Classification Embeddings\"\n",
        "    )\n",
        "\n",
        "    visualize_embeddings(\n",
        "        contrastive_embeddings, contrastive_labels, class_names,\n",
        "        \"Supervised Contrastive Learning Embeddings\"\n",
        "    )\n",
        "\n",
        "    # Visualize training history\n",
        "    visualize_training_history(traditional_history, contrastive_history)\n",
        "\n",
        "    # Compare performance\n",
        "    compare_performance(\n",
        "        traditional_acc, contrastive_acc,\n",
        "        traditional_time, contrastive_time\n",
        "    )\n",
        "\n",
        "    print(\"\\nExperiment completed!\")\n",
        "    print(f\"Traditional Classification - Accuracy: {traditional_acc:.4f}, Training Time: {traditional_time:.2f}s\")\n",
        "    print(f\"Supervised Contrastive Learning - Accuracy: {contrastive_acc:.4f}, Training Time: {contrastive_time:.2f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lpvp96hFf0VG",
        "outputId": "5ff58469-b437-4266-d241-038623af1945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Supervised Contrastive Learning vs Traditional Classification\n",
            "Loading CIFAR-10 dataset...\n",
            "Training data shape: (50000, 32, 32, 3), Training labels shape: (50000,)\n",
            "Test data shape: (10000, 32, 32, 3), Test labels shape: (10000,)\n",
            "\n",
            "--- Traditional Classification Approach ---\n",
            "\n",
            "Training traditional classification model...\n",
            "Epoch 1/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 48ms/step - loss: 1.7645 - sparse_categorical_accuracy: 0.3731 - val_loss: 1.4894 - val_sparse_categorical_accuracy: 0.4726\n",
            "Epoch 2/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - loss: 1.2474 - sparse_categorical_accuracy: 0.5533 - val_loss: 1.4329 - val_sparse_categorical_accuracy: 0.5091\n",
            "Epoch 3/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - loss: 1.0631 - sparse_categorical_accuracy: 0.6211 - val_loss: 1.1955 - val_sparse_categorical_accuracy: 0.6140\n",
            "Epoch 4/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - loss: 0.9376 - sparse_categorical_accuracy: 0.6697 - val_loss: 1.4860 - val_sparse_categorical_accuracy: 0.5624\n",
            "Epoch 5/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - loss: 0.8577 - sparse_categorical_accuracy: 0.6994 - val_loss: 1.1960 - val_sparse_categorical_accuracy: 0.6278\n",
            "Epoch 6/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - loss: 0.7876 - sparse_categorical_accuracy: 0.7217 - val_loss: 1.1019 - val_sparse_categorical_accuracy: 0.6485\n",
            "Epoch 7/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - loss: 0.7416 - sparse_categorical_accuracy: 0.7403 - val_loss: 1.1652 - val_sparse_categorical_accuracy: 0.6487\n",
            "Epoch 8/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - loss: 0.6978 - sparse_categorical_accuracy: 0.7562 - val_loss: 0.9011 - val_sparse_categorical_accuracy: 0.7106\n",
            "Epoch 9/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - loss: 0.6578 - sparse_categorical_accuracy: 0.7705 - val_loss: 0.9169 - val_sparse_categorical_accuracy: 0.7101\n",
            "Epoch 10/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - loss: 0.6249 - sparse_categorical_accuracy: 0.7802 - val_loss: 0.7778 - val_sparse_categorical_accuracy: 0.7525\n",
            "Epoch 11/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - loss: 0.5977 - sparse_categorical_accuracy: 0.7912 - val_loss: 0.7901 - val_sparse_categorical_accuracy: 0.7434\n",
            "Epoch 12/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - loss: 0.5742 - sparse_categorical_accuracy: 0.7995 - val_loss: 0.7320 - val_sparse_categorical_accuracy: 0.7600\n",
            "Epoch 13/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - loss: 0.5542 - sparse_categorical_accuracy: 0.8058 - val_loss: 0.6910 - val_sparse_categorical_accuracy: 0.7732\n",
            "Epoch 14/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - loss: 0.5226 - sparse_categorical_accuracy: 0.8176 - val_loss: 0.9015 - val_sparse_categorical_accuracy: 0.7282\n",
            "Epoch 15/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - loss: 0.5129 - sparse_categorical_accuracy: 0.8225 - val_loss: 0.6681 - val_sparse_categorical_accuracy: 0.7801\n",
            "Epoch 16/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - loss: 0.4890 - sparse_categorical_accuracy: 0.8298 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.7789\n",
            "Epoch 17/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - loss: 0.4716 - sparse_categorical_accuracy: 0.8343 - val_loss: 0.6308 - val_sparse_categorical_accuracy: 0.7904\n",
            "Epoch 18/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - loss: 0.4506 - sparse_categorical_accuracy: 0.8428 - val_loss: 0.7553 - val_sparse_categorical_accuracy: 0.7590\n",
            "Epoch 19/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - loss: 0.4450 - sparse_categorical_accuracy: 0.8447 - val_loss: 0.7290 - val_sparse_categorical_accuracy: 0.7702\n",
            "Epoch 20/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - loss: 0.4287 - sparse_categorical_accuracy: 0.8503 - val_loss: 0.6084 - val_sparse_categorical_accuracy: 0.8010\n",
            "Training completed in 380.83 seconds\n",
            "Test Loss: 0.6084\n",
            "Test Accuracy: 0.8010\n",
            "\n",
            "--- Supervised Contrastive Learning Approach ---\n",
            "\n",
            "Phase 1: Contrastive pre-training...\n",
            "Epoch 1/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 48ms/step - loss: 4.6464 - val_loss: 4.5311\n",
            "Epoch 2/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - loss: 4.4082 - val_loss: 4.6649\n",
            "Epoch 3/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - loss: 4.2987 - val_loss: 4.2632\n",
            "Epoch 4/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - loss: 4.1918 - val_loss: 4.3413\n",
            "Epoch 5/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - loss: 4.0924 - val_loss: 4.2043\n",
            "Epoch 6/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 47ms/step - loss: 4.0063 - val_loss: 4.0811\n",
            "Epoch 7/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - loss: 3.9381 - val_loss: 4.2064\n",
            "Epoch 8/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - loss: 3.8633 - val_loss: 4.0959\n",
            "Epoch 9/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - loss: 3.7979 - val_loss: 4.1777\n",
            "Epoch 10/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - loss: 3.7602 - val_loss: 4.0516\n",
            "Epoch 11/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - loss: 3.7001 - val_loss: 4.0441\n",
            "Epoch 12/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - loss: 3.6597 - val_loss: 3.7719\n",
            "Epoch 13/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - loss: 3.6289 - val_loss: 4.0007\n",
            "Epoch 14/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - loss: 3.5966 - val_loss: 3.7801\n",
            "Epoch 15/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - loss: 3.5557 - val_loss: 3.7681\n",
            "Epoch 16/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - loss: 3.5304 - val_loss: 3.8955\n",
            "Epoch 17/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - loss: 3.4934 - val_loss: 3.6722\n",
            "Epoch 18/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - loss: 3.4724 - val_loss: 3.9294\n",
            "Epoch 19/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - loss: 3.4550 - val_loss: 3.7263\n",
            "Epoch 20/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - loss: 3.4227 - val_loss: 3.7606\n",
            "Pretraining completed in 383.51 seconds\n",
            "Phase 2: Classification training...\n",
            "Epoch 1/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 1.3765 - sparse_categorical_accuracy: 0.6785 - val_loss: 0.5991 - val_sparse_categorical_accuracy: 0.7996\n",
            "Epoch 2/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.5148 - sparse_categorical_accuracy: 0.8260 - val_loss: 0.5993 - val_sparse_categorical_accuracy: 0.7995\n",
            "Epoch 3/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.5102 - sparse_categorical_accuracy: 0.8266 - val_loss: 0.5945 - val_sparse_categorical_accuracy: 0.7998\n",
            "Epoch 4/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.5090 - sparse_categorical_accuracy: 0.8275 - val_loss: 0.5901 - val_sparse_categorical_accuracy: 0.8045\n",
            "Epoch 5/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.5075 - sparse_categorical_accuracy: 0.8271 - val_loss: 0.5963 - val_sparse_categorical_accuracy: 0.8001\n",
            "Epoch 6/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.5105 - sparse_categorical_accuracy: 0.8270 - val_loss: 0.5983 - val_sparse_categorical_accuracy: 0.8008\n",
            "Epoch 7/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.5065 - sparse_categorical_accuracy: 0.8276 - val_loss: 0.5929 - val_sparse_categorical_accuracy: 0.8018\n",
            "Epoch 8/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.5050 - sparse_categorical_accuracy: 0.8297 - val_loss: 0.5844 - val_sparse_categorical_accuracy: 0.8049\n",
            "Epoch 9/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.5040 - sparse_categorical_accuracy: 0.8299 - val_loss: 0.5925 - val_sparse_categorical_accuracy: 0.7998\n",
            "Epoch 10/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.5010 - sparse_categorical_accuracy: 0.8315 - val_loss: 0.5873 - val_sparse_categorical_accuracy: 0.8035\n",
            "Epoch 11/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.4998 - sparse_categorical_accuracy: 0.8298 - val_loss: 0.5860 - val_sparse_categorical_accuracy: 0.8046\n",
            "Epoch 12/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.5013 - sparse_categorical_accuracy: 0.8299 - val_loss: 0.5817 - val_sparse_categorical_accuracy: 0.8060\n",
            "Epoch 13/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.4992 - sparse_categorical_accuracy: 0.8294 - val_loss: 0.5828 - val_sparse_categorical_accuracy: 0.8067\n",
            "Epoch 14/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.4988 - sparse_categorical_accuracy: 0.8298 - val_loss: 0.5836 - val_sparse_categorical_accuracy: 0.8029\n",
            "Epoch 15/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.4989 - sparse_categorical_accuracy: 0.8293 - val_loss: 0.5815 - val_sparse_categorical_accuracy: 0.8049\n",
            "Epoch 16/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.4987 - sparse_categorical_accuracy: 0.8313 - val_loss: 0.5805 - val_sparse_categorical_accuracy: 0.8055\n",
            "Epoch 17/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.4958 - sparse_categorical_accuracy: 0.8320 - val_loss: 0.5797 - val_sparse_categorical_accuracy: 0.8053\n",
            "Epoch 18/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.4956 - sparse_categorical_accuracy: 0.8326 - val_loss: 0.5792 - val_sparse_categorical_accuracy: 0.8072\n",
            "Epoch 19/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.4932 - sparse_categorical_accuracy: 0.8314 - val_loss: 0.5788 - val_sparse_categorical_accuracy: 0.8066\n",
            "Epoch 20/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.4950 - sparse_categorical_accuracy: 0.8323 - val_loss: 0.5779 - val_sparse_categorical_accuracy: 0.8076\n",
            "Classification training completed in 82.78 seconds\n",
            "Total training time: 466.29 seconds\n",
            "Test Loss: 0.5779\n",
            "Test Accuracy: 0.8076\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([6366, 9628, 5916,  681, 5459, 4393, 7048, 7138,  876,  928, 8332,\n       8359, 9149, 3784, 7859, 5296, 3579, 1087, 4352, 1611, 5102, 2618,\n       1346,   53, 3256, 9348, 3978, 3752,  856, 3211, 7992, 5185, 2412,\n       7203, 8497, 2910, 4401, 2370, 4918, 1827, 9518, 1279, 9925, 3277,\n       2127, 9235, 4902, 7176, 9691, 7014, 6166, 4940, 5105, 4165, 9446,\n       1692, 7431, 3077, 7343, 7219, 8117, 4279, 9935, 4688, 1170, 4095,\n       4678, 9241, 6017, 4516, 2585,   93, 2133, 5408, 4780, 4219, 8672,\n       5282,  141, 6016, 6732, 3769, 6410, 9033, 8944, 7777, 6982, 3948,\n        118, 4194, 6202, 7122,  503,  787, 7429, 8145, 6546, 9138, 6555,\n       2392, 5447, 3210, 3519,  859, 3416, 5643, 7322, 5071, 7266, 4309,\n       2448, 2414, 6022, 9853, 1958, 8273, 4436,  728,  322, 6800, 7106,\n       8488, 5061, 4392, 7542, 7422, 7094, 4072, 2864, 5655, 8923, 1821,\n       8900, 2300, 3896, 3581,  193, 1014, 8293, 3399, 7990, 4438, 6545,\n       9627, 8382, 5456, 8203, 9344, 8130, 9621, 3635, 9613, 3315, 7809,\n       5734, 9521, 6716, 3800, 2785, 2968, 2524, 7438, 8792, 6911, 8284,\n       8956, 6419, 7510,  969, 2859, 5939, 7581, 7671, 1961, 2699, 9513,\n        385, 4704, 3590, 2084, 1901, 4941, 5059, 9542, 5119, 5338, 9916,\n       9125, 4143, 7954, 1034, 4411, 2904, 5100, 1493, 1229,  351, 7206,\n       4442, 1535, 3241, 2112, 3457, 5915, 1136, 9603,   75,  807, 7808,\n       1337, 9554, 3826,  955,  478, 8391, 8347, 3668, 2085, 1522, 8568,\n        397, 4109, 3950, 2301, 9369, 3906,  980, 4632, 3429, 4605, 9402,\n       5259, 8433, 7183, 3912, 6087, 9321, 2695, 4013, 9707, 1704, 3287,\n       1752,  297, 7061, 1435, 4609, 2380, 9972, 6605, 6314,  946, 7409,\n       3874, 7489, 5810, 2150, 4322, 3314, 1371, 9994, 3812, 4547, 4732,\n       5442, 2828, 1060, 5242, 4577, 4989, 1412, 2554, 4358, 4024,  409,\n       2843, 3640, 1537, 8628, 6661, 9730,  341, 7174, 9532, 6003, 6713,\n       6427, 4730, 3370, 7591, 5675, 9078, 1527, 7988, 2229, 4821, 9317,\n       3860, 4701, 7153, 7346, 9727, 5564, 8069,  618, 1747, 5317, 6978,\n       8499,  163, 8815, 4936, 9881, 6215, 3329,  484, 3461,  604, 4336,\n        115, 3103, 1504, 9648, 6331, 5630, 9761, 6400,  738, 3958, 2041,\n       3528, 5827,  779, 5215, 7374, 7609, 8553, 1489, 7857, 6592,  790,\n       1826,  687, 4573, 5143, 1423, 2641, 1311,  223, 3608, 4243, 9950,\n       7985, 5755, 9945, 8892, 1132, 3110, 8196, 2907, 7615, 1114, 6602,\n       2480, 7001, 1770, 2140, 6946, 1582, 5047, 3284, 1599, 4625, 7536,\n       8420, 5463, 7947, 9659, 6015, 7865, 6106, 2602, 9476, 3867, 7148,\n       8807,  218, 4731, 2730, 3150, 1968, 9664, 8246, 6175, 5536, 1052,\n       3962, 7766, 6126, 6699, 1738,  438, 7239, 5178, 6952, 9025, 9029,\n       8086, 9269, 4068, 8141,  882, 6588, 5074, 5663,  326, 2839, 9102,\n       5951,  313, 6509, 2026, 6124, 6753, 8426,  251, 4198, 9594, 6985,\n       5846, 4036, 5073, 3733, 6088, 9874, 9654, 1530, 5820, 6114, 1936,\n        136, 9563, 9426, 6210, 8424, 3002,  451, 7016, 3844, 4824,  971,\n       2535, 1729, 9000, 8362, 4922, 8333, 8170, 1930, 7529, 2405, 1271,\n       2647, 2129, 3293, 1350, 2942, 5956, 1678, 8683, 2444, 4640, 5489,\n       3452, 2983, 6585, 2253, 6824, 1030, 7031, 6751,  310, 3468, 3089,\n       2346, 1273, 5943, 7089, 6773, 4906, 1512, 2334, 4371, 3068, 3417,\n        139, 4471, 2177,  940, 3398, 2199, 1604, 1182, 9275, 3230, 4966,\n       1449, 1632, 5474, 5708, 9304, 6719, 2119, 2826, 2242, 1077, 7334,\n       7937, 5701, 3756, 9066, 6467, 2703, 8753, 7348, 7285, 2929, 1644,\n       2801, 5342, 5815, 9968, 3472, 3382, 3121, 1898, 2512, 9198, 6548,\n       2509, 4751, 7907, 7920, 4524, 4212, 8198,  851, 3171, 9004, 1290,\n       9431, 7310, 6979, 2960, 7525, 4415, 5009, 2948, 2265, 2689, 7202,\n       9722, 4855, 9064, 6512, 3294, 8644, 4325, 9997,  424, 3129, 7415,\n       8878, 9796, 3934, 5582, 6301, 8794,  718, 2876, 3762, 9884, 4693,\n       4831, 4667, 2104, 2992, 9105, 2946, 6433, 6193,  936, 4232, 2319,\n       7549, 7914, 2825, 6524, 4254, 5771, 7982, 3575, 2676, 6292, 6750,\n       9803, 3778, 1231, 4630, 1905, 4346, 6076, 5954, 8030, 4706, 7879,\n       3522,  966, 2578, 1092, 4984, 3301, 1117, 1574, 4603, 5748, 5919,\n       4152, 5743, 2719, 2720, 9284, 1911, 5774,  748, 8057, 4043, 8503,\n        221, 3001, 3128, 4193, 4418,  210, 4912,  499, 5507, 6544, 8516,\n       6148,  180, 7923, 6623, 8427, 7141,  186, 7532, 9998,  466, 9418,\n         59, 4189, 6590, 7381, 3652, 3731, 4859, 7538, 1282, 1867, 8599,\n       6617, 4117, 7841, 1131, 8770, 2988, 4195, 9108, 8005, 8020, 2844,\n       2626, 9976, 1027, 3073, 6488, 1147, 3636, 7472, 6703,  828, 7250,\n       6821, 2869, 9765, 9417,  200, 2616, 7981, 5218, 2374, 6637, 5785,\n       2997, 5234, 5744, 9247,  803, 3143, 9851, 4981, 7389, 8790, 3268,\n       2660, 2728, 6228, 1430, 7769, 5500, 9111, 3208, 7655, 2812, 3450,\n       8341, 4032, 1974, 1228, 5859, 2270, 8112, 5177, 4245, 5569, 7066,\n       8869, 6150, 5325, 1657, 8174, 4497, 3426, 6737, 5618, 1978, 9745,\n       5858, 7339, 5245, 3250, 7533, 9216, 4480,  603, 6269, 2885, 8428,\n       8184, 7270, 7592, 5597, 1205,   82, 3893, 4854, 9301, 9806, 5940,\n       6286, 8667, 7223, 1805, 1635, 3649, 2760, 8696, 1084, 8258, 4489,\n       3486, 9732, 5359, 9165, 3278, 7019, 6070, 7465, 8636, 8481, 7969,\n       4005, 8940, 3737, 1355, 8458, 2744, 7104, 2766, 3425, 2193, 5091,\n       9325, 1739, 1899, 6428, 7033, 7578, 5713, 3719, 5481, 1719, 7948,\n       4565, 3400,  126, 8312, 7499,  571, 4226, 1838, 5304, 5549, 8666,\n       8353, 8660, 8242, 9246, 3588, 1453, 9289, 4758, 1312, 3926,  512,\n       8730, 9830, 9218, 6643, 3106, 3180, 7277, 3074,   88, 5329, 8879,\n       3265, 4868, 5016, 5852, 8389, 2600, 3048, 2759, 8992, 8088,  837,\n       6961, 9511, 3935, 4337, 2979, 7120, 9261, 2247, 5877, 9470, 3565,\n       8941, 8132, 9964, 8210, 8038,  670, 3583, 5657,  988, 2878, 2508,\n       8684, 2043, 1768, 8528, 3204,  767, 7137, 3543, 7846,  189, 8887,\n       4797, 5449, 5888, 3024, 9685,  257, 3894, 7869, 4028, 5198, 3482,\n        412, 5829, 2830, 7748,  960, 5148, 8540, 9290, 1402, 4324, 4240,\n       3485, 2295, 8710, 3623, 2592, 3516,   24,  346, 5432, 8986, 8468,\n       4903, 8105, 8742, 6619, 1272, 6918, 5182, 5694, 5246, 2106, 6306,\n       4205, 1510, 9864, 1103, 1997, 7029, 4843, 5683, 3018, 1815, 7892,\n         10, 8966, 1994, 5553, 3376, 4388, 3341, 5475, 8097, 9867, 2462,\n        103, 8682, 9601, 1850,  127, 1013, 9063, 6056, 1378, 1638, 3115,\n       5982, 3559, 9147, 8208,  119, 8414, 7303, 9328, 7882, 1124, 3298,\n       4282, 9682, 9062, 3127, 1307, 9229, 8100, 3753, 7551, 5274, 9748,\n       8263, 3310, 2221, 7154, 4499,  878, 6941, 6866, 2658, 1713])",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-972361fa1b80>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-a8f09ec6a7ca>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Extract embeddings for visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     traditional_embeddings, traditional_labels = extract_embeddings(\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mtraditional_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     )\n",
            "\u001b[0;32m<ipython-input-20-fb6aaa94b1d1>\u001b[0m in \u001b[0;36mextract_embeddings\u001b[0;34m(model, x_data, y_data, num_samples)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Use NumPy indexing directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mx_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0my_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/tensor_getitem_override.py\u001b[0m in \u001b[0;36m_check_index\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# TODO(slebedev): IndexError seems more appropriate here, but it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# will break `_slice_helper` contract.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SLICE_TYPE_ERROR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", got {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([6366, 9628, 5916,  681, 5459, 4393, 7048, 7138,  876,  928, 8332,\n       8359, 9149, 3784, 7859, 5296, 3579, 1087, 4352, 1611, 5102, 2618,\n       1346,   53, 3256, 9348, 3978, 3752,  856, 3211, 7992, 5185, 2412,\n       7203, 8497, 2910, 4401, 2370, 4918, 1827, 9518, 1279, 9925, 3277,\n       2127, 9235, 4902, 7176, 9691, 7014, 6166, 4940, 5105, 4165, 9446,\n       1692, 7431, 3077, 7343, 7219, 8117, 4279, 9935, 4688, 1170, 4095,\n       4678, 9241, 6017, 4516, 2585,   93, 2133, 5408, 4780, 4219, 8672,\n       5282,  141, 6016, 6732, 3769, 6410, 9033, 8944, 7777, 6982, 3948,\n        118, 4194, 6202, 7122,  503,  787, 7429, 8145, 6546, 9138, 6555,\n       2392, 5447, 3210, 3519,  859, 3416, 5643, 7322, 5071, 7266, 4309,\n       2448, 2414, 6022, 9853, 1958, 8273, 4436,  728,  322, 6800, 7106,\n       8488, 5061, 4392, 7542, 7422, 7094, 4072, 2864, 5655, 8923, 1821,\n       8900, 2300, 3896, 3581,  193, 1014, 8293, 3399, 7990, 4438, 6545,\n       9627, 8382, 5456, 8203, 9344, 8130, 9621, 3635, 9613, 3315, 7809,\n       5734, 9521, 6716, 3800, 2785, 2968, 2524, 7438, 8792, 6911, 8284,\n       8956, 6419, 7510,  969, 2859, 5939, 7581, 7671, 1961, 2699, 9513,\n        385, 4704, 3590, 2084, 1901, 4941, 5059, 9542, 5119, 5338, 9916,\n       9125, 4143, 7954, 1034, 4411, 2904, 5100, 1493, 1229,  351, 7206,\n       4442, 1535, 3241, 2112, 3457, 5915, 1136, 9603,   75,  807, 7808,\n       1337, 9554, 3826,  955,  478, 8391, 8347, 3668, 2085, 1522, 8568,\n        397, 4109, 3950, 2301, 9369, 3906,  980, 4632, 3429, 4605, 9402,\n       5259, 8433, 7183, 3912, 6087, 9321, 2695, 4013, 9707, 1704, 3287,\n       1752,  297, 7061, 1435, 4609, 2380, 9972, 6605, 6314,  946, 7409,\n       3874, 7489, 5810, 2150, 4322, 3314, 1371, 9994, 3812, 4547, 4732,\n       5442, 2828, 1060, 5242, 4577, 4989, 1412, 2554, 4358, 4024,  409,\n       2843, 3640, 1537, 8628, 6661, 9730,  341, 7174, 9532, 6003, 6713,\n       6427, 4730, 3370, 7591, 5675, 9078, 1527, 7988, 2229, 4821, 9317,\n       3860, 4701, 7153, 7346, 9727, 5564, 8069,  618, 1747, 5317, 6978,\n       8499,  163, 8815, 4936, 9881, 6215, 3329,  484, 3461,  604, 4336,\n        115, 3103, 1504, 9648, 6331, 5630, 9761, 6400,  738, 3958, 2041,\n       3528, 5827,  779, 5215, 7374, 7609, 8553, 1489, 7857, 6592,  790,\n       1826,  687, 4573, 5143, 1423, 2641, 1311,  223, 3608, 4243, 9950,\n       7985, 5755, 9945, 8892, 1132, 3110, 8196, 2907, 7615, 1114, 6602,\n       2480, 7001, 1770, 2140, 6946, 1582, 5047, 3284, 1599, 4625, 7536,\n       8420, 5463, 7947, 9659, 6015, 7865, 6106, 2602, 9476, 3867, 7148,\n       8807,  218, 4731, 2730, 3150, 1968, 9664, 8246, 6175, 5536, 1052,\n       3962, 7766, 6126, 6699, 1738,  438, 7239, 5178, 6952, 9025, 9029,\n       8086, 9269, 4068, 8141,  882, 6588, 5074, 5663,  326, 2839, 9102,\n       5951,  313, 6509, 2026, 6124, 6753, 8426,  251, 4198, 9594, 6985,\n       5846, 4036, 5073, 3733, 6088, 9874, 9654, 1530, 5820, 6114, 1936,\n        136, 9563, 9426, 6210, 8424, 3002,  451, 7016, 3844, 4824,  971,\n       2535, 1729, 9000, 8362, 4922, 8333, 8170, 1930, 7529, 2405, 1271,\n       2647, 2129, 3293, 1350, 2942, 5956, 1678, 8683, 2444, 4640, 5489,\n       3452, 2983, 6585, 2253, 6824, 1030, 7031, 6751,  310, 3468, 3089,\n       2346, 1273, 5943, 7089, 6773, 4906, 1512, 2334, 4371, 3068, 3417,\n        139, 4471, 2177,  940, 3398, 2199, 1604, 1182, 9275, 3230, 4966,\n       1449, 1632, 5474, 5708, 9304, 6719, 2119, 2826, 2242, 1077, 7334,\n       7937, 5701, 3756, 9066, 6467, 2703, 8753, 7348, 7285, 2929, 1644,\n       2801, 5342, 5815, 9968, 3472, 3382, 3121, 1898, 2512, 9198, 6548,\n       2509, 4751, 7907, 7920, 4524, 4212, 8198,  851, 3171, 9004, 1290,\n       9431, 7310, 6979, 2960, 7525, 4415, 5009, 2948, 2265, 2689, 7202,\n       9722, 4855, 9064, 6512, 3294, 8644, 4325, 9997,  424, 3129, 7415,\n       8878, 9796, 3934, 5582, 6301, 8794,  718, 2876, 3762, 9884, 4693,\n       4831, 4667, 2104, 2992, 9105, 2946, 6433, 6193,  936, 4232, 2319,\n       7549, 7914, 2825, 6524, 4254, 5771, 7982, 3575, 2676, 6292, 6750,\n       9803, 3778, 1231, 4630, 1905, 4346, 6076, 5954, 8030, 4706, 7879,\n       3522,  966, 2578, 1092, 4984, 3301, 1117, 1574, 4603, 5748, 5919,\n       4152, 5743, 2719, 2720, 9284, 1911, 5774,  748, 8057, 4043, 8503,\n        221, 3001, 3128, 4193, 4418,  210, 4912,  499, 5507, 6544, 8516,\n       6148,  180, 7923, 6623, 8427, 7141,  186, 7532, 9998,  466, 9418,\n         59, 4189, 6590, 7381, 3652, 3731, 4859, 7538, 1282, 1867, 8599,\n       6617, 4117, 7841, 1131, 8770, 2988, 4195, 9108, 8005, 8020, 2844,\n       2626, 9976, 1027, 3073, 6488, 1147, 3636, 7472, 6703,  828, 7250,\n       6821, 2869, 9765, 9417,  200, 2616, 7981, 5218, 2374, 6637, 5785,\n       2997, 5234, 5744, 9247,  803, 3143, 9851, 4981, 7389, 8790, 3268,\n       2660, 2728, 6228, 1430, 7769, 5500, 9111, 3208, 7655, 2812, 3450,\n       8341, 4032, 1974, 1228, 5859, 2270, 8112, 5177, 4245, 5569, 7066,\n       8869, 6150, 5325, 1657, 8174, 4497, 3426, 6737, 5618, 1978, 9745,\n       5858, 7339, 5245, 3250, 7533, 9216, 4480,  603, 6269, 2885, 8428,\n       8184, 7270, 7592, 5597, 1205,   82, 3893, 4854, 9301, 9806, 5940,\n       6286, 8667, 7223, 1805, 1635, 3649, 2760, 8696, 1084, 8258, 4489,\n       3486, 9732, 5359, 9165, 3278, 7019, 6070, 7465, 8636, 8481, 7969,\n       4005, 8940, 3737, 1355, 8458, 2744, 7104, 2766, 3425, 2193, 5091,\n       9325, 1739, 1899, 6428, 7033, 7578, 5713, 3719, 5481, 1719, 7948,\n       4565, 3400,  126, 8312, 7499,  571, 4226, 1838, 5304, 5549, 8666,\n       8353, 8660, 8242, 9246, 3588, 1453, 9289, 4758, 1312, 3926,  512,\n       8730, 9830, 9218, 6643, 3106, 3180, 7277, 3074,   88, 5329, 8879,\n       3265, 4868, 5016, 5852, 8389, 2600, 3048, 2759, 8992, 8088,  837,\n       6961, 9511, 3935, 4337, 2979, 7120, 9261, 2247, 5877, 9470, 3565,\n       8941, 8132, 9964, 8210, 8038,  670, 3583, 5657,  988, 2878, 2508,\n       8684, 2043, 1768, 8528, 3204,  767, 7137, 3543, 7846,  189, 8887,\n       4797, 5449, 5888, 3024, 9685,  257, 3894, 7869, 4028, 5198, 3482,\n        412, 5829, 2830, 7748,  960, 5148, 8540, 9290, 1402, 4324, 4240,\n       3485, 2295, 8710, 3623, 2592, 3516,   24,  346, 5432, 8986, 8468,\n       4903, 8105, 8742, 6619, 1272, 6918, 5182, 5694, 5246, 2106, 6306,\n       4205, 1510, 9864, 1103, 1997, 7029, 4843, 5683, 3018, 1815, 7892,\n         10, 8966, 1994, 5553, 3376, 4388, 3341, 5475, 8097, 9867, 2462,\n        103, 8682, 9601, 1850,  127, 1013, 9063, 6056, 1378, 1638, 3115,\n       5982, 3559, 9147, 8208,  119, 8414, 7303, 9328, 7882, 1124, 3298,\n       4282, 9682, 9062, 3127, 1307, 9229, 8100, 3753, 7551, 5274, 9748,\n       8263, 3310, 2221, 7154, 4499,  878, 6941, 6866, 2658, 1713])"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}